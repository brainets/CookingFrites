{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8160c3e0-01a8-4bd4-85b5-63d315e874a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **--- `WfMi` : Measuring information AND perform statistics ---**\n",
    "---\n",
    "\n",
    "In this tutorial, we're going to go through the following points :\n",
    "1. How to perform Fixed- and Random-Effect analysis\n",
    "2. How to correct for multiple comparisons both at the test- and cluster-wise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68666509-891c-49cd-8055-d109321fe462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from mne.utils import ProgressBar\n",
    "\n",
    "from frites.dataset import DatasetEphy\n",
    "from frites.workflow import WfMi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211db77-eb0c-49f0-9a07-53d2a6a82dda",
   "metadata": {},
   "source": [
    "---\n",
    "# **--- ROOT PATH ---**\n",
    "\n",
    "<div class=\"alert alert-info\"><p>\n",
    "\n",
    "Define the path to where the data are located !\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b18d7-87a6-4e9f-a0e1-7f07743fbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/run/media/etienne/DATA/Toolbox/BraiNets/CookingFrites/dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abad188-4731-4b4d-9bf0-c4db6614cd26",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# **0 - Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb874d-d2b7-45fb-88c0-4c86476663cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "###############################################################################\n",
    "#                 Load the data of a single subject\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def load_ss(subject_nb):\n",
    "    \"\"\"Load the data of a single subject.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subject_nb : int\n",
    "        Subject number [0, 12]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hga : xarray.DataArray\n",
    "        Xarray containing the high-gamma activity\n",
    "    anat : pandas.DataFrame\n",
    "        Table containing the anatomical informations\n",
    "    beh : pandas.DataFrame\n",
    "        Table containing the behavioral informations\n",
    "    \"\"\"\n",
    "    # load the high-gamma activity\n",
    "    file_hga = os.path.join(ROOT, 'hga', f'hga_s-{subject_nb}.nc')\n",
    "    hga = xr.load_dataarray(file_hga)\n",
    "\n",
    "    # load the name of the brain regions\n",
    "    file_anat = os.path.join(ROOT, 'anat', f'anat_s-{subject_nb}.xlsx')\n",
    "    anat = pd.read_excel(file_anat)\n",
    "\n",
    "    # load the behavior\n",
    "    file_beh = os.path.join(ROOT, 'beh', f'beh_s-{subject_nb}.xlsx')\n",
    "    beh = pd.read_excel(file_beh)\n",
    "    \n",
    "    return hga, anat, beh\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#                 Load the data of multiple subjects\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def load_ms(s_range=[0, 11], model='outcome', condition='rew',\n",
    "            space='channels', mean_roi=True, prepend_suj_to_ch=True):\n",
    "    \"\"\"Load multiple subjects.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s_range : int or list\n",
    "        Subjects to load. Use either an integer (e.g. 7) to load a single\n",
    "        subject or a range of subjects (e.g. [5, 10])\n",
    "    model : {'outcome', 'pe', 'rt'}\n",
    "        Model to use. Use either :\n",
    "        \n",
    "            * 'outcome' : find differences in the neural activity between the\n",
    "              outcomes\n",
    "            * 'pe' : find regions with an activity correlating with the\n",
    "              prediction error\n",
    "            * 'rt' : find regions with an activity correlating with the\n",
    "              reaction time\n",
    "    condition : {'rew', 'pun', 'context', 'null'}\n",
    "        Condition to load. Use either :\n",
    "        \n",
    "            * 'rew' : for outcomes {+0€; +1€}\n",
    "            * 'pun' : for outcomes {-1€; -0€}\n",
    "            * 'context' : for outcomes {-1€; +1€}\n",
    "            * 'null' : for outcomes {-0€; +0€}\n",
    "    space : {'channels', 'roi'}\n",
    "        Specify if the spatial dimension should be described with channel names\n",
    "        or with brain region names\n",
    "    mean_roi : bool\n",
    "        Specify if you want to take the mean high-gamma activity inside a brain\n",
    "        region\n",
    "    prepend_suj_to_ch : bool\n",
    "        Add subject name to each channel name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hga : list\n",
    "        List of high-gamma activity across subjects\n",
    "    \"\"\"\n",
    "    # inputs checking\n",
    "    if isinstance(s_range, int):\n",
    "        s_range = [s_range, s_range]\n",
    "    s_range[1] += 1\n",
    "    s_range[0], s_range[1] = max(s_range[0], 0), min(s_range[1], 12)\n",
    "    mesg = f\"Subject %i | model={model} | condition={condition} | space={space}\"\n",
    "    pbar = ProgressBar(range(s_range[0], s_range[1]), mesg=mesg % 0)\n",
    "    model = model.lower()\n",
    "    assert space in ['channels', 'parcels', 'roi']\n",
    "    \n",
    "    # get the code of the condition\n",
    "    outc = {\n",
    "        'rew': (+1, +2),\n",
    "        'pun': (-2, -1),\n",
    "        'context': (-2, +2),\n",
    "        'null': (-1, +1)\n",
    "    }[condition]\n",
    "    \n",
    "    # get the behavioral column to use\n",
    "    col = {\n",
    "        'outcome': 'code',\n",
    "        'pe': 'PE',\n",
    "        'rt': 'RT'\n",
    "    }[model]\n",
    "    \n",
    "    # load the data\n",
    "    hga = []\n",
    "    for n_s in range(s_range[0], s_range[1]):\n",
    "        pbar._tqdm.desc = mesg % n_s\n",
    "        # load the data of a single subject\n",
    "        _hga, _anat, _beh = load_ss(n_s)\n",
    "        _outc = _hga['trials'].data\n",
    "        _ch = _hga['channels'].data\n",
    "        \n",
    "        # replace trial dimension with the model\n",
    "        _hga = _hga.rename(trials=model)\n",
    "        _hga[model] = list(_beh[col])\n",
    "        \n",
    "        # get which outcome to keep\n",
    "        keep_outc = np.logical_or(_outc == outc[0], _outc == outc[1])\n",
    "        _hga = _hga[keep_outc, ...]\n",
    "        \n",
    "        # replace with brain regions\n",
    "        if space in ['parcels', 'roi']:\n",
    "            _hga = _hga.rename(channels=space)\n",
    "            _hga[space] = list(_anat['roi'])\n",
    "            \n",
    "            # take the mean of the hga per parcel\n",
    "            if mean_roi:\n",
    "                _hga = _hga.groupby(space).mean(space)\n",
    "        elif prepend_suj_to_ch and (space == 'channels'):\n",
    "            # prepend subject number to channel name\n",
    "            _hga['channels'] = [f\"suj{n_s}/{c}\" for c in _ch]\n",
    "        \n",
    "        # ascontinuous array\n",
    "        _hga.data = np.ascontiguousarray(_hga.data)\n",
    "        \n",
    "        hga.append(_hga)\n",
    "        pbar.update_with_increment_value(1)\n",
    "\n",
    "    return hga\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#                           Plotting the results\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def _single_subplot(mi, pv, pv_on_top, pv_pos, lw=5, color='r', alpha=0.05,\n",
    "                    label=None, xlabel=True, ylabel=True):\n",
    "    \"\"\"Single subplot plotting function.\"\"\"\n",
    "    times = mi['times'].data\n",
    "    \n",
    "    if pv_on_top:\n",
    "        p = np.full((len(times),), pv_pos)\n",
    "        p[pv.data >= alpha] = np.nan\n",
    "        plt.plot(times, mi.data, color=color, label=label, lw=1.5)\n",
    "        plt.plot(times, p, color=color, lw=lw)\n",
    "    else:\n",
    "        mi_s = mi.copy()\n",
    "        mi_s.data[pv >= alpha] = np.nan\n",
    "        plt.plot(times, mi.data, color=color, label=label, lw=1.5)\n",
    "        plt.plot(times, mi_s.data, color=color, lw=lw)\n",
    "    plt.axvline(0., color='k', linestyle='--', lw=1)\n",
    "    if xlabel: plt.xlabel('Times')\n",
    "    if ylabel: plt.ylabel('MI (bits)')\n",
    "    plt.xlim(-.5, 1.5)\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "def plot_results(mi, pv, alpha=0.05, split=True, pv_on_top=True, lw=5):\n",
    "    \"\"\"Plot significant results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mi, pv : xr.DataArray\n",
    "        Measure of information and corrected p-values of shape (n_times, n_roi)\n",
    "    alpha : float\n",
    "        Significiency threshold\n",
    "    split : bool\n",
    "        Specify whether results should be presented in splitted subplots (True)\n",
    "        or superimposed in the same subplot (False)\n",
    "    pv_on_top : bool\n",
    "        Specify whether the significant values should be plotted on top (True)\n",
    "        or along the line\n",
    "    lw : float\n",
    "        Line width of significant results\n",
    "    \"\"\"\n",
    "    times, roi = mi['times'].data, np.sort(mi['roi'].data)\n",
    "    mimax, mimin = mi.data.max(), mi.data.min()\n",
    "    dp = (mimax - mimin) / 20.\n",
    "    \n",
    "    if split:\n",
    "        # figure creation\n",
    "        n_per_row = 5\n",
    "        ncols = min(n_per_row, len(roi))\n",
    "        nrows = int(np.ceil(len(roi) / n_per_row))\n",
    "        width, height = int(5 * ncols), int(4 * nrows)\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=nrows, ncols=ncols, sharex=True, sharey=True,\n",
    "            figsize=(width, height))\n",
    "        axs = np.ravel(axs)\n",
    "\n",
    "        # subplot filling\n",
    "        for n_r in range(len(axs)):\n",
    "            plt.sca(axs[n_r])\n",
    "            if n_r >= len(roi):\n",
    "                plt.axis(False)\n",
    "                continue\n",
    "            r = roi[n_r]\n",
    "            _single_subplot(\n",
    "                mi.sel(roi=r), pv.sel(roi=r), pv_on_top, mimax + dp,\n",
    "                lw=lw, color=f'C{n_r}', alpha=alpha, label=r,\n",
    "                xlabel=n_r >= len(roi) - n_per_row, ylabel=n_r % n_per_row == 0\n",
    "            )\n",
    "            fw = 'bold' if np.any(pv.sel(roi=r).data < 0.05) else None\n",
    "            plt.title(r, fontweight=fw)\n",
    "    else:\n",
    "        # subplot filling\n",
    "        fig = plt.figure(figsize=(15, 8))\n",
    "        for n_r, r in enumerate(roi):\n",
    "            _single_subplot(\n",
    "                mi.sel(roi=r), pv.sel(roi=r), pv_on_top, mimax + dp * (n_r + 1),\n",
    "                lw=lw, color=f'C{n_r}', alpha=alpha, label=r\n",
    "            )\n",
    "        plt.legend()\n",
    "    \n",
    "    # add figure title\n",
    "    attrs = mi.attrs\n",
    "    mi_type, inference, mcp = attrs['mi_type'], attrs['inference'], attrs['mcp']\n",
    "    fig.suptitle(\n",
    "        (f\"Significant results using {inference.upper()} model and p-values \"\n",
    "         f\"corrected using {mcp} (p < {alpha}; mi_type={mi_type})\"),\n",
    "        fontweight='bold', fontsize=18, y=1.02# + int(split)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa4300-303c-4fad-adc0-a366b55bc0a3",
   "metadata": {},
   "source": [
    "---\n",
    "# **1. Fixed and Random-Effects**\n",
    "\n",
    "## 1.1 Fixed-effect (FFX) analysis\n",
    "\n",
    "<div class=\"alert alert-success\"><p>\n",
    "\n",
    "**When using a fixed-effect?**\n",
    "\n",
    "Some general rules :\n",
    "- With limited data (e.g. one or two monkeys, single subject, several contacts)\n",
    "- When you assume that the effect is relatively reproducible in a population (e.g. the activity of several contacts inside a brain region) \n",
    "    \n",
    "Something to keep in mind is that, if you want for example to perform a FFX across several contacts inside a brain region, and if one or two of those contacts present some bad activity (e.g. epileptic spikes), it can affects the representation of the population !\n",
    "</p></div>\n",
    "\n",
    "### 1.1.1 Perform a fixed-effect on a single subject (contact level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113c0df-b57c-473d-88d1-da7c0d8e8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a single subject\n",
    "hga = load_ms(s_range=7, model='pe', condition='rew', space='channels')\n",
    "ds = DatasetEphy(hga, y='pe', times='times', roi='channels')\n",
    "\n",
    "# stat settings\n",
    "inference = 'ffx'  # Fixed-effect model\n",
    "n_perm = 50        # number of permutations (the higher, the better ! 1000 recommended)\n",
    "n_jobs = -1        # parallel computing. -1 = Use all cores\n",
    "random_state = 0   # fix the random state of the machine. Reproducibility\n",
    "\n",
    "\n",
    "# run the computations and stats\n",
    "wf = WfMi(inference=inference, mi_type='cc')\n",
    "mi, pv = wf.fit(ds, n_perm=n_perm, n_jobs=n_jobs, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e8d8d-9290-4041-8541-e3e27d9810a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(mi, pv, split=True, pv_on_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f86110-ffd7-4431-a416-413add0253ea",
   "metadata": {},
   "source": [
    "### Perform a fixed-effect across subjects (contact level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0ab4e-47f2-4eb8-8fc7-f5acefe904d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all\n",
    "hga = load_ms(s_range=[3, 5], model='pe', condition='rew', space='channels')\n",
    "ds = DatasetEphy(hga, y='pe', times='times', roi='channels')\n",
    "\n",
    "# run the computations and stats\n",
    "wf = WfMi(inference='ffx', mi_type='cc')\n",
    "mi, pv = wf.fit(ds, n_perm=50, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058af47f-4268-4169-94eb-caf7d59c1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(mi, pv, split=True, pv_on_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e9863-d5bb-4350-9b1d-b307af3a1393",
   "metadata": {},
   "source": [
    "### 1.1.2 Perform a fixed-effect across subjects (roi level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bec3a-c1f0-417c-af81-5201a6b8315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all\n",
    "hga = load_ms(model='pe', condition='rew', space='roi')\n",
    "ds = DatasetEphy(hga, y='pe', times='times', roi='roi')\n",
    "\n",
    "# run the computations and stats\n",
    "wf = WfMi(inference='ffx', mi_type='cc')\n",
    "mi, pv = wf.fit(ds, n_perm=50, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403aac1-1ad5-4ea8-a093-d5de60f0268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(mi, pv, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653c8ef-b091-4532-820a-28d9af2174b5",
   "metadata": {},
   "source": [
    "## 1.2 Random-effect (RFX) analysis\n",
    "\n",
    "<div class=\"alert alert-success\"><p>\n",
    "\n",
    "**When using a random-effect?**\n",
    "\n",
    "Some general rules :\n",
    "- When you have a sufficient amount of data\n",
    "- When you want to take into consideration the variability inter-samples inside a population\n",
    "</p></div>\n",
    "\n",
    "### 1.2.1 Perform a random-effect across subjects (roi level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0bbe6-9851-489d-b2d1-16d3a5352b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all\n",
    "hga = load_ms(model='pe', condition='rew', space='roi')\n",
    "ds = DatasetEphy(hga, y='pe', times='times', roi='roi')\n",
    "\n",
    "# run the computations and stats\n",
    "wf = WfMi(inference='rfx', mi_type='cc')\n",
    "mi, pv = wf.fit(ds, n_perm=50, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd72c9c-0bc1-482a-b986-b6d149b4205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(mi, pv, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8429a86-64c7-4087-8a52-bfff0e8fe81d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><p>\n",
    "\n",
    "If we compare this result to the one using the FFX, you'll see that the dorso lateral prefrontal cortex didn't came out as significant. This could be explained by the fact that there's variability across subjects inside this region and this variability is correctly captured by the RFX (and not the FFX)\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae94955-0ef4-4f18-9a3f-ac6b02eb967c",
   "metadata": {},
   "source": [
    "### 1.2.2 Perform a random-effect across contacts _(hacking Frites)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6080cf-5bd7-4617-be0d-788e93243cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading several subjects\n",
    "hga = load_ms(model='pe', condition='rew', space='roi',\n",
    "              mean_roi=False)\n",
    "\n",
    "# data need to be organized differently\n",
    "hga_rfx = []\n",
    "for h in hga:\n",
    "    hga_rfx += [h.isel(roi=[k]) for k in range(len(h['roi']))]\n",
    "\n",
    "ds = DatasetEphy(hga_rfx, y='pe', times='times', roi='roi')\n",
    "\n",
    "# run the computations and stats\n",
    "wf = WfMi(inference='rfx', mi_type='cc')\n",
    "mi, pv = wf.fit(ds, n_perm=50, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4188b7-96ff-403a-bca1-4b000db9f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(mi, pv, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5e8a8-7881-459c-b1bf-e7f761240e58",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><p>\n",
    "\n",
    "In the context of this sEEG data, modeling random variations across contacts inside a brain region and therefore, avoiding taking the mean of the HGA inside it would probably be the best choice to keep all of the information that is contained inside each sEEG contact. But it's also the method that is the most computationaly intensive !\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64fa4a-a6bf-4b6b-9b29-0cbcad283751",
   "metadata": {},
   "source": [
    "---\n",
    "# **2. Correcting p-values for multiple comparisons**\n",
    "## 2.1 Cluster-based vs. test-wise corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b23d1c-dcc7-48cf-b9f3-df9b3da47690",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = [\n",
    "    'cluster-wise/cluster',\n",
    "    'test-wise/fdr', 'test-wise/maxstat'\n",
    "]\n",
    "\n",
    "@interact(mcp=mcp)\n",
    "def plot(mcp='cluster-wise/cluster'):\n",
    "    # loading a single subject\n",
    "    hga = load_ms(s_range=1, model='pe', condition='pun', space='channels')\n",
    "    ds = DatasetEphy(hga, y='pe', times='times', roi='channels', verbose=False)\n",
    "\n",
    "    # run the computations and stats\n",
    "    mcp = mcp.split('/')[1]\n",
    "    wf = WfMi(inference='ffx', mi_type='cc', verbose=False)\n",
    "    mi, pv = wf.fit(ds, n_perm=50, n_jobs=-1, random_state=0, mcp=mcp)\n",
    "    \n",
    "    plot_results(mi, pv, split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c12cd-29e7-47de-8a3e-2d2d4b114e32",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><p>\n",
    "\n",
    "Cluster >> FDR ~ MAXSTAT\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da0c9de-01fb-496e-9df9-465a8f5d0bd3",
   "metadata": {},
   "source": [
    "---\n",
    "# **---- Test yourself ! ----**\n",
    "## **1. Fixed and Random effect**\n",
    "### 1.1 Differences between the zeros\n",
    "\n",
    "<div class=\"alert alert-warning\"><p>\n",
    "\n",
    "**[Instructions]**\n",
    "\n",
    "One interesting question that can be asked on this data is **are there brain regions for which the activity is modulated differently whether the subjects are experiencing outcomes 0€ during the reward condition (i.e. +0€) or during the punishement condition (-0€)**. Said differently, are there any brain regions showing different activity between the outcome -0€ and +0€?\n",
    "    \n",
    "Try to answer this question (`condition='null'`), by loading the data of **all of the subjects**, pick the **outcome** (`model`) as the task-related variable and use the **brain regions** for describing the spatial dimension (`space`). Then use a random-effect model (`inference`) combined to cluster-based statistics.\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d805616-f5ce-452a-909b-b6e3b53860d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6b596-6da3-427f-9761-5c1034a3cec2",
   "metadata": {},
   "source": [
    "### 1.2 Correlation with reaction time \n",
    "\n",
    "<div class=\"alert alert-warning\"><p>\n",
    "\n",
    "**[Instructions]**\n",
    "\n",
    "Using a **Fixed-effect (FFX)** model, identify the **brain regions** that correlates with the **reaction time** during the **reward condition**.\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3307a83-171a-410d-ade2-fb7ea45bc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95791e7c-2193-4a20-bec9-286ae89ade4c",
   "metadata": {},
   "source": [
    "## **2. Correcting for multiple comparisons**\n",
    "### 2.1 The single time-point problem (advanced)\n",
    "\n",
    "<div class=\"alert alert-warning\"><p>\n",
    "\n",
    "**[Instructions]**\n",
    "\n",
    "An interesting question is **how to detect temporal clusters if i've a single time point?**. For example, imagin that you want to contrast baseline vs. period of interest. In that case, it doesn't make sense to use cluster-based statistics. So you can directly use \"test-wise\" methods for correcting (FDR, maximum statistics etc.).\n",
    "    \n",
    "Below, I build a dataset to investigate baseline vs. period of interest. Now it's your turn to find **which channel of this subject present an activity different between the baseline and the period of interest**. To solve this problem, you'll have to decide whether you should perform FFX / RFX such as which method for correcting p-values for multiple comparisons.\n",
    "</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3b657-b56b-41a4-a7a6-0ff48f223e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "hga = load_ms(s_range=2, model='outcome', condition='null', space='channels'\n",
    "              prepend_suj_to_ch=False)\n",
    "\n",
    "# build the baseline dataset\n",
    "hga_tr = []\n",
    "for k in range(len(hga)):\n",
    "    # build baseline and period-of-interest high-gamma\n",
    "    hga_bsl = hga[k].sel(times=0.).drop('times')\n",
    "    hga_poi = hga[k].sel(times=.25).drop('times')\n",
    "    \n",
    "    # rename the outcome dimension\n",
    "    hga_bsl = hga_bsl.rename(outcome='period')\n",
    "    hga_poi = hga_poi.rename(outcome='period')\n",
    "    \n",
    "    # use the code 0 = baseline; 1 = poi\n",
    "    hga_bsl['period'] = [0] * len(hga_bsl['period'])\n",
    "    hga_poi['period'] = [1] * len(hga_poi['period'])\n",
    "    \n",
    "    # concatenate both and expand with a time dimension\n",
    "    _hga_tr = xr.concat([hga_bsl, hga_poi], 'period')\n",
    "    _hga_tr = _hga_tr.expand_dims('times', axis=2)\n",
    "    _hga_tr['times'] = [0.]\n",
    "    \n",
    "    # append to the full list\n",
    "    hga_tr.append(_hga_tr)\n",
    "\n",
    "# build the DatasetEphy\n",
    "ds = DatasetEphy(hga_tr, y='period', times='times', roi='channels')\n",
    "\n",
    "# your turn !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ea3da-c29d-414f-bab6-aa2709a389f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
